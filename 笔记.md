总共四个步骤，以及6个参数

步骤：
1. 取新轮胎
    在轮胎架上取出一个轮胎
     * 有不同尺寸的轮胎
     * 有靶标（可能），
     * 精度要求不高，大致对齐就行
     * 主要是中心大致对齐轮轴，部分误差无所谓
2. 拆旧轮胎
    * 对齐轮轴即可 这里需要视觉匹配
    * 实际上也得考虑俯仰滚转角度，通过激光模块测量角度，但是不用考虑轮胎旋转
    * 拆完后倒退1m左右
3. 装配新轮胎
    * 在拆下旧轮胎之后，AGV进行180°旋转
    * 此时距离轮轴大概1m
    * 轮轴侧略微垫起来，保证在更换轮胎时轮胎不接地，这样造成一个角度倾斜，和水平方向夹角不超过7°
    * 根据距离、激光测量模块调整粗识别、俯仰和滚转角度，粗对齐到距离车轴端面0.3m左右
    * 在到达0.3m时，开始精确校准，调整各项参数，我不明白为啥刚才简报里说是只拍摄一张或者20fps，这个我知道对实时性要求不高
    * 推入前后我想弄一个实时给出反馈来确保精度，毕竟这个不是简单的对上对不上
    * 如果推入过程中AGV发生失速证明未对齐，进行重新对齐，首先考虑的是俯仰角度，然后是滚转角度，如果都未对齐则AGV会向后退重新开始之前的步骤
4. 放回旧轮胎
    * 在1m左右检测备胎架，稍微上抬然后对齐中心靶标（或者大致对齐中心）向前放回 

参数:

自订，与方案中具体使用可能有不同点

1. x轴偏移量（平行于轮轴时水平方向的偏移量）
2. y轴偏移量（平行于轮轴时竖直方向的偏移量）
3. z轴偏移量（AGV与轮轴间距）* 实际上靠别的模块，但是这个参数于粗细识别相关
4. ω俯仰角度
5. φ滚转角度 * 实际上靠别的模块
6. α轮胎旋转角度 配合另一个相机对比

一些要点
1. 相机
    * 主摄像机：备胎视觉检测模块
        * 型号 MV-CS050-10GM-PRO
            * 分辨率 2448*2048
            * 靶面尺寸	2/3”
            * 像元尺寸	3.45 μm × 3.45 μm
            * 最大帧率	24.2 fps @2448 × 2048 Mono 8；35.6 fps @2448 × 2048 Mono 8(开启无损压缩)
            * 数据接口	Gigabit Ethernet(1000 Mbit/s)兼容Fast Ethernet(100 Mbit/s)
            * 传感器型号	Sony IMX264
        * 镜头 MVL-MF1618M-5MPE
            * 焦距  16mm
            * F数 F1.8~F16
            * 最近摄距 0.2m
    * 辅助摄像机：备胎辅助视觉检测模块
        * 型号	MV-CA020-10GM
            * 分辨率    1624*1240
            * 靶面尺寸	1/1.7’’
            * 像元尺寸	4.5 µm × 4.5 µm
            * 最大帧率	60 fps @1624x1240
            * 数据接口	GigE
            * 传感器型号	IMX430
        * 镜头	MVL-HF0624M-10MP
            * 焦距 6 mm 
            * F数 F2.4~F16
            * 最近摄距 0.1 m 

根据不同尺寸的轮胎调整相机位置，保证轮胎的中心点在相机视野中；

需要在识别中根据识别的结果给出AGV的运动指令，这里之前是用人工，现在全自动化

激光并非平行，而是向上下左右四个方向略偏来提升测距测角的测量精度、



原方案部分内容：

相机采集图像，首先利用螺母模板进行检测，若检测不到螺母，则说明轮胎的螺母已完全拆除，可继续进行定位，否则发出报警，提醒人工对残余螺母进行处理，待处理完毕后才可进行定位；系统再采集一帧图像，对图像预处理后通过模板匹配算法快速定位轮胎轮毂ROI，用Hough变换对轮胎轮毂外沿圆形边缘进行提取后使用目标定位算法并结合车轴平面检测算法定位轮胎相对相机位置以及车轴与水平面夹角。



备胎安装定位
备胎安装时激光点打在车轴端面人工借助激光点位置调整全向智能小车与车轴相对位置，当全向智能小车进入合适位置后指示灯闪烁以提醒操作员可以切换为自动模式—备胎安装。
首先定位备胎螺栓孔位置，即检测备胎螺栓孔与过备胎圆心垂线夹角λ，由相机采集图像，如图所示。y为过备胎圆心垂线、RL为已知螺栓孔圆心与备胎圆心距离、x为螺栓孔圆心与过备胎圆心垂线距离，所以λ可由式3-1求得。
然后定位车轴位置，伸缩杆伸长一定距离避免轮毂内径遮挡相机视野，由相机采集图像，系统对图像预处理后通过模板匹配算法快速定位车轴ROI，用Hough变换对车轴外沿圆形边缘以及10个圆形螺栓轮廓边缘进行提取，使用目标定位算法定位车轴相对相机位置以及螺栓相对垂直过车轴圆心的直线的夹角如图所示，（X0，Y0）为图像坐标系原点，（X1，Y1）为车轴中心点，（x0，y0）、（x1，y1）、……（x9，y9）分别为10个螺栓中心点。最后结合车轴平面检测算法计算车轴平面与相机平面俯仰轴夹角以及俯翻滚轴夹角。通过上述，实现备胎自动安装推入功能。



根据试验台设计算法，实际上和最后要的算法差不多，但是因为是实验环境下可能简单一些
在实际工作场景可能多点增加鲁棒性的附加内容

考虑采用传统视觉方案进行识别对比，比如目标匹配，使用一些特征提取
工程应用用不到太fancy的算法my ass
能用好用fancy不fancy有啥呢，电脑性能的话实在不行就优化剪枝
分辨率应该是够用了，但是电脑性能我猜有限
我自己的话考虑写点机器学习的内容，如果用的上就更好了

拔旧轮胎的方面没有俯仰角度，相当于少考虑一个参数

老师提到了多模态，这个之后再看看
这个纯扯淡，没有文字也没有音频，也不能指望加个麦克风听工人骂人

1320mm的轮胎和轮毂，重点在轮毂，再来点螺栓和螺母


# 算法内容

目标检测定位算法
目标检测算法主要通过模板匹配算法和目标定位算法计算目标与相机的位姿关系，算法主要包括图像预处理、特征提取、模板匹配、坐标转换等，具体流程如下：
1)图像预处理
用于提高原始图像的质量，提高识别精度。主要包括畸变处理、混合中值滤波、Laplace锐化处理、图像均衡化，分别起到畸变校正、降噪、锐化、增强对比度等作用；
2)特征提取
用于目标轮廓的特征信息，如颜色特征、角点特征、HOG特征等，主要采用Harris角点检测算法分别获取锁紧机构左右两侧二维码靶标角点特征；
3)模板匹配
基于多特征共生矩阵模板匹配算法，通过对目标图像多个特征进行融合，将图像特征量化为k个簇类，通过求解共生矩阵来统计每个簇类对在目标图像中共同出现的次数，并采用共生统计的方法来求解每个簇类的共生概率，从而寻找最优匹配位置，有效地提高检测精度。
4)位姿计算
用于轮胎、轮毂、螺栓和螺栓孔等圆形轮廓定位，下面以轮胎定位为例阐述其原理，已知相机焦距f，拍摄视野角度2β和轮胎半径L，图中M1和L1分别是通过Hough变换提取的轮胎图片的圆心像素值和半径像素值,图像的像素尺寸为𝑛×𝑚，根据式5-1和5-2就可以将M1和L1的像素尺寸转化为厘米单位。
其中L1’和OM1’分别为轮胎图片中轮胎的半径值和轮胎圆心到图片中的距离值，单位为cm。根据相似三角形原理即可求得相机距离轮胎中心的距离OcM。
轮胎的圆心M与图像中的轮胎的圆心M1与相机中心OC在一条直线上，所以M1与图片中心的夹角就是M与相机之间的角度。
6)坐标转换
位姿计算后，即可计算轮胎相对相机的位姿，再通过坐标转换，计算车轴圆心与在全向智能车体坐标系中位置（x、y、z）和姿态（俯仰角β、回转角θ）。


我觉得不应该使用传统目标匹配，下次开会时候说一下，不过应该先弄点demo啥的出来，再弄个表出来一下
如果电脑的性能够用真就用ai就行，加上分辨率管够，用个成熟的yolov8堆上去就行

如果要判断距离，在最初的轮胎架等地方上做个标尺，然后我觉得可以通过距离和pixels来判断需要的距离
也就是标定一下，就能给出信号挪多远，我的想法是每次移动之后进行重新对比位置，然后给出信号，一次次修正，直到对齐

在对齐的过程中，给出一些移动建议，我虽然更推荐实时检测的，但是fps只有20性能也有限，项目原案也是使用一张图片进行检测是否对齐



### 改进的方案五：结合传统CV和深度学习的综合对齐方案

#### 系统架构

1. **数据采集模块**
   - **主相机**：500万像素黑白相机，安装在轮胎拆卸机构中心，用于对齐识别。
   - **辅助相机**：200万像素黑白相机，安装位置相对主相机较向下，用于辅助检测轮胎的旋转角度是否对齐。
   - **激光雷达**：四个激光雷达，分别用于测量前后、上下、左右的距离和角度。

2. **预处理模块**
   - **图像预处理**：对主相机和辅助相机采集的图像进行灰度化、去噪等预处理操作。
   - **激光雷达数据处理**：对激光雷达数据进行滤波和校正，提取有用的距离和角度信息。

3. **深度学习模型**
   - **目标检测模型**：使用YOLO、SSD或Faster R-CNN等目标检测模型，检测轮胎的位置和姿态。
   - **姿态预测模型**：使用轻量级的CNN模型或回归模型，预测轮胎的俯仰角、旋转角度和左右角度。这些模型可以是基于Transformer的模型，如EfficientNet或MobileNet，以提高预测速度和性能。

4. **传统CV模块**
   - **特征匹配**：使用SIFT或SURF等特征点检测与匹配技术，进行更精确的对齐。
   - **Hough变换**：检测轮胎边缘或轮廓，计算轮胎中心与目标位置的偏移量。
   - **螺母检测**：使用Hough圆变换或边缘检测技术，检测螺栓上的螺母是否拆卸完全。

5. **融合模块**
   - **数据融合**：将深度学习模型的预测结果与激光雷达数据进行融合，生成最终的对齐和姿态调整参数。
   - **卡尔曼滤波器**：使用卡尔曼滤波器对深度学习模型的预测结果和激光雷达数据进行融合，提高姿态预测的稳定性和精度。
   - **控制指令生成**：根据融合后的数据生成电机的控制指令，调整轮胎装卸机构的位置和姿态。

6. **控制模块**
   - **电机控制**：根据生成的控制指令，驱动电机进行精确的对齐和调整。
   - **反馈机制**：通过实时监控和反馈机制，确保对齐和调整的精度和稳定性。

#### 具体流程

1. **数据采集**
   - **主相机采集**：在轮胎与架子、车体等距离1m时，拍摄一张图像。
   - **辅助相机采集**：拍摄一张轮胎旋转情况的图像。
   - **激光雷达采集**：使用四个激光雷达分别测量前后、上下、左右的距离和角度。

2. **预处理**
   - 对主相机和辅助相机的图像进行灰度化、去噪等预处理操作。
   - 对激光雷达数据进行滤波和校正，提取有用的距离和角度信息。

3. **深度学习模型预测**
   - 使用目标检测模型检测轮胎的位置和姿态。
   - 使用轻量级的CNN模型或回归模型预测轮胎的俯仰角、旋转角度和左右角度。

4. **传统CV模块**
   - **特征匹配**：使用SIFT或SURF等特征点检测与匹配技术，进行更精确的对齐。
   - **Hough变换**：检测轮胎边缘或轮廓，计算轮胎中心与目标位置的偏移量。
   - **螺母检测**：使用Hough圆变换或边缘检测技术，检测螺栓上的螺母是否拆卸完全。

5. **数据融合**
   - 将深度学习模型的预测结果与激光雷达数据进行融合，生成最终的对齐和姿态调整参数。
   - 使用卡尔曼滤波器对深度学习模型的预测结果和激光雷达数据进行融合，提高姿态预测的稳定性和精度。
   - 根据融合后的数据生成电机的控制指令，调整轮胎装卸机构的位置和姿态。

6. **控制执行**
   - 根据生成的控制指令，驱动电机进行精确的对齐和调整。
   - 实时监控和反馈机制，确保对齐和调整的精度和稳定性。

7. **二次检测**
   - **主相机拍摄**：在电机调整完成后，再次拍摄一张图像。
   - **辅助相机拍摄**：再次拍摄一张轮胎旋转情况的图像。
   - **激光雷达测量**：再次测量前后、上下、左右的距离和角度。

8. **预处理**
   - 对主相机和辅助相机的图像进行灰度化、去噪等预处理操作。
   - 对激光雷达数据进行滤波和校正，提取有用的距离和角度信息。

9. **深度学习模型预测**
   - 使用目标检测模型检测轮胎的位置和姿态。
   - 使用轻量级的CNN模型或回归模型预测轮胎的俯仰角、旋转角度和左右角度。

10. **传统CV模块**
    - **特征匹配**：使用SIFT或SURF等特征点检测与匹配技术，进行更精确的对齐。
    - **Hough变换**：检测轮胎边缘或轮廓，计算轮胎中心与目标位置的偏移量。
    - **螺母检测**：使用Hough圆变换或边缘检测技术，检测螺栓上的螺母是否拆卸完全。

11. **数据融合**
    - 将深度学习模型的预测结果与激光雷达数据进行融合，生成最终的对齐和姿态调整参数。
    - 使用卡尔曼滤波器对深度学习模型的预测结果和激光雷达数据进行融合，提高姿态预测的稳定性和精度。
    - 根据融合后的数据生成电机的控制指令，调整轮胎装卸机构的位置和姿态。

12. **控制执行**
    - 根据生成的控制指令，驱动电机进行精确的对齐和调整。
    - 实时监控和反馈机制，确保对齐和调整的精度和稳定性。

### 具体参数和要求

- **轮胎大小**：1320mm或更大。
- **初始检测距离**：1m。
- **车体角度**：与水平方向角度低于10度。
- **整体精度**：1mm。

### 速度与精度的考量

1. **初始检测**
   - **速度优先**：在初始检测阶段，主要目的是快速获取轮胎的大致位置和姿态。使用轻量级的目标检测模型（如YOLO或MobileNet）和激光雷达数据，快速生成初步的对齐和姿态调整参数。
   - **精度要求**：初步对齐和姿态调整的精度可以稍微放宽，主要确保轮胎的大致位置和姿态正确。

2. **控制执行**
   - **精度优先**：在控制执行阶段，需要确保轮胎的精确定位和姿态调整。使用传统的CV技术（如SIFT、Hough变换）和卡尔曼滤波器，结合激光雷达数据，生成高精度的对齐和姿态调整参数。
   - **速度要求**：虽然精度是首要考虑，但控制执行的速度也不能太慢，以确保整个过程的流畅性。

3. **二次检测**
   - **精度优先**：在电机调整完成后，进行二次检测以确保对齐和姿态调整的高精度。使用深度学习模型和传统CV技术，结合激光雷达数据，生成最终的对齐和姿态调整参数。
   - **速度要求**：二次检测的时间可以适当延长，以确保最终的对齐和姿态调整达到1mm的精度要求。

### 注意事项

- **相机帧率**：相机仅支持20fps，因此每次检测时只拍摄一张图像。
- **多次检测**：在每次电机调整完成后，进行二次检测以确保对齐精度。
- **实时反馈**：通过实时监控和反馈机制，确保对齐和调整的精度和稳定性。


下面是来源于Poe的Sonnet输出：
算法思路
1. 有轮胎情况
预处理：去噪、对比度增强
轮廓检测：寻找圆形/椭圆形结构
圆形拟合：找到轮胎的外圆和可能的内圆(轮毂)
中心确定：基于检测到的圆确定轴心
2. 无轮胎情况
预处理：增强边缘和局部对比度
边缘检测：提取车轴轮廓
形态学处理：去除杂质和噪声
圆形/椭圆检测：寻找车轴的圆形特征
轴心计算：通过圆形/椭圆的中心确定轴心
项目结构

复制
AxleLocalization/
├── CMakeLists.txt
├── src/
│   ├── main.cpp
│   ├── axle_detector.cpp
│   ├── axle_detector.h
│   ├── utils.cpp
│   └── utils.h
├── include/
└── test_images/
代码实现
1. CMakeLists.txt
cmake

复制
cmake_minimum_required(VERSION 3.10)
project(AxleLocalization)

set(CMAKE_CXX_STANDARD 14)
set(CMAKE_CXX_STANDARD_REQUIRED ON)

# 查找OpenCV包
find_package(OpenCV REQUIRED)
include_directories(${OpenCV_INCLUDE_DIRS})

# 包含头文件目录
include_directories(${PROJECT_SOURCE_DIR}/include)

# 添加可执行文件
add_executable(axle_localization
    src/main.cpp
    src/axle_detector.cpp
    src/utils.cpp
)

# 链接OpenCV库
target_link_libraries(axle_localization ${OpenCV_LIBS})
2. axle_detector.h
cpp

复制
#ifndef AXLE_DETECTOR_H
#define AXLE_DETECTOR_H

#include <opencv2/opencv.hpp>
#include <string>

class AxleDetector {
public:
    AxleDetector();
    
    // 主处理函数：检测车轴中心
    cv::Point2f detectAxleCenter(const cv::Mat& image, bool hasTire, cv::Mat& outputImage);
    
private:
    // 图像预处理函数
    cv::Mat preprocessImage(const cv::Mat& image, bool hasTire);
    
    // 有轮胎情况下的定位
    cv::Point2f locateWithTire(const cv::Mat& processedImage, cv::Mat& outputImage);
    
    // 无轮胎情况下的定位
    cv::Point2f locateWithoutTire(const cv::Mat& processedImage, cv::Mat& outputImage);
    
    // 辅助函数：标记轴心位置
    void markAxleCenter(cv::Mat& image, const cv::Point2f& center);
    
    // 辅助函数：圆形拟合
    std::vector<cv::Vec3f> detectCircles(const cv::Mat& image);
    
    // 辅助函数：椭圆拟合
    std::vector<cv::RotatedRect> detectEllipses(const cv::Mat& image);
    
    // 参数
    int cannyThreshold1;
    int cannyThreshold2;
    int minRadius;
    int maxRadius;
    double circleAccumThreshold;
};

#endif // AXLE_DETECTOR_H
3. axle_detector.cpp
cpp

复制
#include "axle_detector.h"
#include <iostream>

AxleDetector::AxleDetector() {
    // 初始化参数
    cannyThreshold1 = 50;
    cannyThreshold2 = 150;
    minRadius = 30;
    maxRadius = 300;
    circleAccumThreshold = 30;
}

cv::Point2f AxleDetector::detectAxleCenter(const cv::Mat& image, bool hasTire, cv::Mat& outputImage) {
    // 预处理图像
    cv::Mat processedImage = preprocessImage(image, hasTire);
    
    // 根据是否有轮胎选择不同的定位方法
    cv::Point2f center;
    if (hasTire) {
        center = locateWithTire(processedImage, outputImage);
    } else {
        center = locateWithoutTire(processedImage, outputImage);
    }
    
    // 复制原图到输出图像
    if (outputImage.empty()) {
        image.copyTo(outputImage);
    }
    
    // 标记轴心位置
    markAxleCenter(outputImage, center);
    
    return center;
}

cv::Mat AxleDetector::preprocessImage(const cv::Mat& image, bool hasTire) {
    cv::Mat result;
    
    // 转为灰度图
    if (image.channels() > 1) {
        cv::cvtColor(image, result, cv::COLOR_BGR2GRAY);
    } else {
        image.copyTo(result);
    }
    
    // 基本去噪
    cv::GaussianBlur(result, result, cv::Size(5, 5), 0);
    
    // 根据是否有轮胎调整预处理参数
    if (hasTire) {
        // 对比度增强
        cv::normalize(result, result, 0, 255, cv::NORM_MINMAX);
    } else {
        // 局部自适应阈值处理，处理光照不均
        cv::adaptiveThreshold(result, result, 255, cv::ADAPTIVE_THRESH_GAUSSIAN_C, 
                             cv::THRESH_BINARY_INV, 15, 2);
        
        // 形态学操作去除小噪点
        int morphSize = 2;
        cv::Mat element = cv::getStructuringElement(cv::MORPH_ELLIPSE, 
                                                  cv::Size(2*morphSize + 1, 2*morphSize + 1));
        cv::morphologyEx(result, result, cv::MORPH_OPEN, element);
    }
    
    return result;
}

cv::Point2f AxleDetector::locateWithTire(const cv::Mat& processedImage, cv::Mat& outputImage) {
    // 复制处理过的图像
    cv::Mat display;
    cv::cvtColor(processedImage, display, cv::COLOR_GRAY2BGR);
    
    // 边缘检测
    cv::Mat edges;
    cv::Canny(processedImage, edges, cannyThreshold1, cannyThreshold2);
    
    // 寻找圆形
    std::vector<cv::Vec3f> circles = detectCircles(edges);
    
    // 如果没有找到圆形，尝试寻找椭圆
    if (circles.empty()) {
        std::vector<cv::RotatedRect> ellipses = detectEllipses(edges);
        
        if (!ellipses.empty()) {
            // 使用最大的椭圆中心
            cv::RotatedRect largestEllipse = ellipses[0];
            for (const auto& ellipse : ellipses) {
                if (ellipse.size.area() > largestEllipse.size.area()) {
                    largestEllipse = ellipse;
                }
            }
            
            // 绘制椭圆
            cv::ellipse(display, largestEllipse, cv::Scalar(0, 255, 0), 2);
            display.copyTo(outputImage);
            
            return largestEllipse.center;
        }
        
        // 如果没有找到圆形或椭圆，返回图像中心
        display.copyTo(outputImage);
        return cv::Point2f(processedImage.cols / 2.0f, processedImage.rows / 2.0f);
    }
    
    // 找到了圆形，可能有多个，选择最可能的轮胎圆
    cv::Vec3f bestCircle = circles[0];
    for (const auto& circle : circles) {
        // 假设最大的圆是轮胎
        if (circle[2] > bestCircle[2]) {
            bestCircle = circle;
        }
    }
    
    // 绘制检测到的圆
    cv::Point center(cvRound(bestCircle[0]), cvRound(bestCircle[1]));
    int radius = cvRound(bestCircle[2]);
    cv::circle(display, center, radius, cv::Scalar(0, 0, 255), 2);
    
    display.copyTo(outputImage);
    return cv::Point2f(bestCircle[0], bestCircle[1]);
}

cv::Point2f AxleDetector::locateWithoutTire(const cv::Mat& processedImage, cv::Mat& outputImage) {
    // 复制处理过的图像
    cv::Mat display;
    cv::cvtColor(processedImage, display, cv::COLOR_GRAY2BGR);
    
    // 轮廓检测
    std::vector<std::vector<cv::Point>> contours;
    cv::findContours(processedImage.clone(), contours, cv::RETR_EXTERNAL, cv::CHAIN_APPROX_SIMPLE);
    
    // 如果没有找到轮廓，返回图像中心
    if (contours.empty()) {
        display.copyTo(outputImage);
        return cv::Point2f(processedImage.cols / 2.0f, processedImage.rows / 2.0f);
    }
    
    // 寻找最大的轮廓
    int largestContourIdx = 0;
    double largestArea = 0;
    for (int i = 0; i < contours.size(); i++) {
        double area = cv::contourArea(contours[i]);
        if (area > largestArea) {
            largestArea = area;
            largestContourIdx = i;
        }
    }
    
    // 拟合椭圆或圆形
    if (contours[largestContourIdx].size() >= 5) {
        cv::RotatedRect ellipse = cv::fitEllipse(contours[largestContourIdx]);
        cv::ellipse(display, ellipse, cv::Scalar(0, 255, 0), 2);
        display.copyTo(outputImage);
        return ellipse.center;
    }
    
    // 如果不能拟合椭圆，使用轮廓的中心矩
    cv::Moments mu = cv::moments(contours[largestContourIdx]);
    cv::Point2f center;
    if (mu.m00 != 0) {
        center = cv::Point2f(mu.m10 / mu.m00, mu.m01 / mu.m00);
    } else {
        center = cv::Point2f(processedImage.cols / 2.0f, processedImage.rows / 2.0f);
    }
    
    // 绘制轮廓
    cv::drawContours(display, contours, largestContourIdx, cv::Scalar(0, 255, 0), 2);
    display.copyTo(outputImage);
    
    return center;
}

void AxleDetector::markAxleCenter(cv::Mat& image, const cv::Point2f& center) {
    // 画十字标记
    int markerSize = 20;
    cv::line(image, 
             cv::Point(center.x - markerSize, center.y),
             cv::Point(center.x + markerSize, center.y),
             cv::Scalar(0, 0, 255), 2);
    cv::line(image, 
             cv::Point(center.x, center.y - markerSize),
             cv::Point(center.x, center.y + markerSize),
             cv::Scalar(0, 0, 255), 2);
    
    // 画圆形标记
    cv::circle(image, center, 5, cv::Scalar(0, 0, 255), -1);
    
    // 标注坐标
    std::string text = "(" + std::to_string(int(center.x)) + ", " + std::to_string(int(center.y)) + ")";
    cv::putText(image, text, cv::Point(center.x + 10, center.y - 10),
                cv::FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(0, 0, 255), 1);
}

std::vector<cv::Vec3f> AxleDetector::detectCircles(const cv::Mat& image) {
    std::vector<cv::Vec3f> circles;
    
    // 霍夫圆变换
    cv::HoughCircles(image, circles, cv::HOUGH_GRADIENT, 1,
                    image.rows/8,  // 最小圆心距离
                    100, 30,       // Canny高阈值，圆心累加器阈值
                    minRadius, maxRadius); // 最小和最大半径
    
    return circles;
}

std::vector<cv::RotatedRect> AxleDetector::detectEllipses(const cv::Mat& image) {
    std::vector<cv::RotatedRect> ellipses;
    
    // 查找轮廓
    std::vector<std::vector<cv::Point>> contours;
    cv::findContours(image.clone(), contours, cv::RETR_LIST, cv::CHAIN_APPROX_SIMPLE);
    
    // 对每个轮廓拟合椭圆
    for (const auto& contour : contours) {
        // 轮廓点数必须大于等于5才能拟合椭圆
        if (contour.size() >= 5) {
            cv::RotatedRect ellipse = cv::fitEllipse(contour);
            
            // 过滤掉过小或过大的椭圆
            float radius = (ellipse.size.width + ellipse.size.height) / 4.0;
            if (radius >= minRadius && radius <= maxRadius) {
                ellipses.push_back(ellipse);
            }
        }
    }
    
    return ellipses;
}
4. utils.h
cpp

复制
#ifndef UTILS_H
#define UTILS_H

#include <opencv2/opencv.hpp>
#include <string>

// 实用工具函数声明
namespace Utils {
    // 保存结果图像
    bool saveImage(const std::string& filename, const cv::Mat& image);
    
    // 显示结果
    void showResult(const std::string& windowName, const cv::Mat& image);
    
    // 增强图像对比度
    cv::Mat enhanceContrast(const cv::Mat& image);
    
    // 应用自适应阈值
    cv::Mat applyAdaptiveThreshold(const cv::Mat& image);
}

#endif // UTILS_H
5. utils.cpp
cpp

复制
#include "utils.h"
#include <iostream>

namespace Utils {

bool saveImage(const std::string& filename, const cv::Mat& image) {
    try {
        cv::imwrite(filename, image);
        std::cout << "Image saved as: " << filename << std::endl;
        return true;
    } catch (const cv::Exception& ex) {
        std::cerr << "Error saving image: " << ex.what() << std::endl;
        return false;
    }
}

void showResult(const std::string& windowName, const cv::Mat& image) {
    cv::namedWindow(windowName, cv::WINDOW_NORMAL);
    cv::imshow(windowName, image);
    cv::waitKey(0);
}

cv::Mat enhanceContrast(const cv::Mat& image) {
    cv::Mat result;
    
    // 如果是彩色图像，转换到LAB色彩空间增强亮度通道
    if (image.channels() == 3) {
        cv::Mat labImage;
        cv::cvtColor(image, labImage, cv::COLOR_BGR2Lab);
        
        // 分离通道
        std::vector<cv::Mat> labChannels(3);
        cv::split(labImage, labChannels);
        
        // 对亮度通道进行直方图均衡化
        cv::equalizeHist(labChannels[0], labChannels[0]);
        
        // 合并通道
        cv::merge(labChannels, labImage);
        
        // 转换回BGR
        cv::cvtColor(labImage, result, cv::COLOR_Lab2BGR);
    } else {
        // 灰度图像直接进行直方图均衡化
        cv::equalizeHist(image, result);
    }
    
    return result;
}

cv::Mat applyAdaptiveThreshold(const cv::Mat& image) {
    cv::Mat result;
    
    // 确保输入为灰度图
    cv::Mat grayImage;
    if (image.channels() > 1) {
        cv::cvtColor(image, grayImage, cv::COLOR_BGR2GRAY);
    } else {
        grayImage = image;
    }
    
    // 应用自适应阈值
    cv::adaptiveThreshold(grayImage, result, 255, 
                         cv::ADAPTIVE_THRESH_GAUSSIAN_C,
                         cv::THRESH_BINARY_INV, 21, 5);
    
    return result;
}

}
6. main.cpp
cpp

复制
#include <iostream>
#include <string>
#include "axle_detector.h"
#include "utils.h"

void printUsage() {
    std::cout << "Usage: axle_localization <image_path> [--with-tire/--without-tire]" << std::endl;
    std::cout << "Options:" << std::endl;
    std::cout << "  --with-tire     Process image with tire (default)" << std::endl;
    std::cout << "  --without-tire  Process image without tire" << std::endl;
}

int main(int argc, char** argv) {
    // 解析命令行参数
    if (argc < 2) {
        std::cerr << "Error: Missing image path" << std::endl;
        printUsage();
        return -1;
    }
    
    std::string imagePath = argv[1];
    bool hasTire = true;  // 默认有轮胎
    
    // 解析可选参数
    if (argc > 2) {
        std::string option = argv[2];
        if (option == "--without-tire") {
            hasTire = false;
        } else if (option != "--with-tire") {
            std::cerr << "Error: Unknown option: " << option << std::endl;
            printUsage();
            return -1;
        }
    }
    
    // 读取图像
    cv::Mat image = cv::imread(imagePath);
    if (image.empty()) {
        std::cerr << "Error: Could not read image from " << imagePath << std::endl;
        return -1;
    }
    
    std::cout << "Processing image: " << imagePath << std::endl;
    std::cout << "Mode: " << (hasTire ? "With tire" : "Without tire") << std::endl;
    
    // 创建检测器并处理图像
    AxleDetector detector;
    cv::Mat outputImage;
    cv::Point2f axleCenter = detector.detectAxleCenter(image, hasTire, outputImage);
    
    // 输出结果
    std::cout << "Axle center found at: (" << axleCenter.x << ", " << axleCenter.y << ")" << std::endl;
    
    // 保存结果图像
    std::string outputFilename = "axle_detection_result.jpg";
    Utils::saveImage(outputFilename, outputImage);
    
    // 显示结果图像
    Utils::showResult("Axle Detection Result", outputImage);
    
    return 0;
}
实现说明
算法逻辑：
预处理阶段通过去噪和增强操作减少干扰
有轮胎情况使用圆形检测（霍夫变换）找到轮胎轮廓
无轮胎情况使用轮廓检测和椭圆拟合找到车轴
处理倾斜情况通过椭圆拟合来适应不同角度
光照问题通过自适应阈值和对比度增强解决
鲁棒性考虑：
适应不同光照条件：使用自适应阈值处理
污渍和背景干扰：通过形态学操作和轮廓过滤
倾斜角度：采用椭圆拟合方法适应不同视角
当算法无法找到明确的轴心时，返回图像中心作为备选
输出：
控制台打印轴心坐标
在图像上标注轴心位置（十字标记+坐标标签）
保存标注后的结果图像
优化方向
如果在实际应用中发现准确率不足，可以考虑以下优化方向：

增加边缘检测和圆形检测的参数自适应机制
添加基于梯度的轴心检测方法
结合多种方法的结果进行加权融合
针对特定场景的预处理参数调整
使用这套方案，您可以在不依赖训练模型的情况下，较为稳健地检测车轴中心位置。

您需要根据实际使用的图像情况对参数进行调整，特别是圆形检测的半径范围和阈值参数。

希望这个解决方案能够满足您的需求！
